#!/usr/bin/env python

import glob
from argh import arg
import argh
from colorama import init, Fore, Back, Style
from hubward import validation
from hubward import log
from hubward import utils
import string
from trackhub import Track, default_hub, CompositeTrack, ViewTrack
from trackhub.track import SubGroupDefinition
from fabric.colors import blue
from trackhub.upload import upload_hub, upload_track, upload_file
import logging
import subprocess
import os
import json
from textwrap import dedent
import yaml
import pkg_resources
import argparse


@arg('lab', help='Lab (or subdirectory) to build trackhub from')
@arg('genome', help='Genome assembly name to use')
@arg('--hub_only', help='Do not upload all tracks, just the hub text files')
@arg('--study', help='Only prepare a hub for the specified study.')
@arg('--config', help='Path to config file')
@arg('--hub_url_pattern',
     help="Override 'hub_url_pattern' specified in config")
@arg('--hub_remote_pattern',
     help="Override 'hub_remote_pattern' specified in config")
@arg('--user', help="Override 'user' specified in config")
@arg('--host', help="Override 'host' specified in config")
@arg('--email', help="Override 'email' specified in config")
def build_trackhub(lab, genome, hub_only=False, study=None,
                   config=os.path.expanduser('~/.hubward.yaml'),
                   hub_url_pattern=None, hub_remote_pattern=None, user=None,
                   host=None, email=None):
    """
    Build a UCSC track hub out of all subdirectories in `lab` directory that
    have a created `metadata.yaml` file and uploads the hub text files and all
    corresponding data and documentation files to the server specified in the
    config file.

    Config file
    -----------
    The config file should be in YAML format file with the following entries
    (edited to reflect your servers). Available place holders are [genome,
    lab].

        # Contents of config file (default location: ~/.hubward.yaml)
        host: example.com
        user: me

        # Externally visible URL to hub when served by host
        hub_url_pattern: http://example.com/apps/{lab}/{genome}/compiled/compiled.hub.txt

        # Absolute path on host, as used by rsync
        hub_remote_pattern: /home/me/apps/{lab}/{genome}/compiled/compiled.hub.txt

        # UCSC asks that you provide email so they can track usage
        email: me@example.com

    """

    config = utils.load_config(config)

    # Build a connected hub using trackhub package
    hub, genomes_file, genome_, trackdb = default_hub(
        hub_name='%stracks' % lab,
        genome=genome,
        short_label='%s' % lab.title(),
        long_label='%s tracks' % lab.title(),
        email=config['email'])

    # Specify hub's url and remote_fn based on config file
    hub.url = config['hub_url_pattern'].format(lab=lab, genome=genome)
    hub.remote_fn = config['hub_remote_pattern'].format(lab=lab, genome=genome)

    # Look for all studies that have an existing metadata.yaml file. For each
    # of those,
    # - re-generate the metadata.yaml file by calling the metadata-builder.py
    #    script
    # - validate the YAML file
    # - create a composite track, and attach all configured tracks to it.
    #
    # See the validation.Study class for details on this processing.
    unique_names = set()
    for metadata_filename in glob.glob('%s/*/metadata.yaml' % lab):
        dirname = os.path.join(
            os.path.dirname(metadata_filename))
        cmds = ['cd', dirname, '&&', 'python', 'metadata-builder.py']
        os.system(' '.join(cmds))

        composite = composite_from_study(validation.Study(metadata_filename))
        trackdb.add_tracks(composite)

    # Render and upload the hub to the server specified in the config.
    hub.render()
    kwargs = dict(host=config['host'], user=config['user'],
                  rsync_options='-avrL --progress')
    upload_hub(hub=hub, **kwargs)
    if not hub_only:
        for track, level in hub.leaves(Track):
            upload_track(track=track, **kwargs)
            pass

    print
    print blue(hub.url)
    print


@arg('lab', help='Lab (or subdirectory) to process files from')
@arg('--force',
     help='Force the re-generation of output files for this study. '
     'Use the special string "ALL" to force re-running everything')
@arg('--prioritize',
     help='Process this subdirectory first. Useful for when you are '
     'first developing a new study')
def process(lab, force=False, prioritize=None):
    def process_study(metadata_filename, force=False):
        s = validation.Study(metadata_filename)
        log('Study: {0.description}, in "{0.dirname}"'.format(s),
            style=Fore.BLUE)
        for d in s.data:
            if d.needs_update() or force:
    """
    Process raw data files into files ready to be uploaded as a track hub.

    For each subdirectory in `lab` that contains a `metadata.yaml` file, it is
    re-generated by calling the respective `metadata-builder.py` script.

    For each of the configured "data" items in the metadata, checks to see if
    an update is needed (i.e., if input is newer than output or if output
    doesn't exist). If so, calls the configured script with the configured
    input and output file arguments.
    """
    if prioritize:
        def priority(fn):
            if fn.startswith(prioritize):
                return 0
            return 1
        studies = sorted(studies, key=priority)
    for filename in studies:
        dirname = os.path.dirname(filename)
        cmds = ['cd', dirname, '&&', 'python', 'metadata-builder.py']
        os.system(' '.join(cmds))

        metadata_filename = os.path.join(dirname, 'metadata.yaml')
        study = os.path.basename(os.path.dirname(metadata_filename))
        force = False
        if (study == force) or (force == 'ALL'):
            force = True
        process_study(metadata_filename, force=force)


def new(lab, label):
    """
    Initializes a new study.
    """
    here = os.path.dirname(__file__)

    dirs = [
        'raw-data',
        'processed-data',
        'processed-data/bed',
        'processed-data/bam',
        'processed-data/bigwig',
        'processed-data/bigbed',
        'src']

    for d in dirs:
        os.system('mkdir -p %s' % (os.path.join(lab, label, d)))

    files = {
        'README': 'Info about processing %s' % label,
        'src/get-data.bash': utils.get_resource('get-data.bash'),
        'metadata-builder.py': utils.get_resource(
            'metadata_builder_template.py'),
        'src/process.py': utils.get_resource('process_template.py'),
      }
    for f, c in files.items():
        if not os.path.exists(f):
            with open(os.path.join(lab, label, f), 'w') as fout:
                fout.write(c + '\n')
            if f == 'src/process.py':
                os.system('chmod +x %s' % os.path.join(lab, label, f))
        else:
            print f, 'exists, skipping'

if __name__ == "__main__":
    import argparse
    argh.dispatch_commands([
        process,
        new,
        build_trackhub,
    ])
